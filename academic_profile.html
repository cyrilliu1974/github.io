<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="0" />
 <title>Hung-Ming Liu | Academic Profile</title>
  <style>
    body {
      font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
      background-color: #f4f7f9;
      color: #333;
      margin: 0;
      padding: 3rem;
      line-height: 1.6;
    }
    .container {
      max-width: 900px;
      margin: auto;
      background: #ffffff;
      padding: 2.5rem;
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
      border-radius: 12px;
    }
    header {
      text-align: center;
      padding-bottom: 1.5rem;
      border-bottom: 2px solid #e0e0e0;
    }
    h1 {
      font-size: 2.5rem;
      color: #1a2a4b;
      margin-bottom: 0.5rem;
    }
    h2 {
      font-size: 1.8rem;
      color: #1a2a4b;
      border-bottom: 1px solid #c0c0c0;
      padding-bottom: 0.5rem;
      margin-top: 2.5rem;
    }
    a {
      color: #007bff;
      text-decoration: none;
      transition: color 0.3s;
    }
    a:hover {
      color: #0056b3;
      text-decoration: underline;
    }
    .links a {
      margin: 0 0.8rem;
      font-size: 1.1rem;
    }
    .publication {
      margin-bottom: 2rem;
    }
    .publication h3 {
      font-size: 1.3rem;
      color: #333;
      margin-top: 0;
      margin-bottom: 0.5rem;
    }
    .abstract {
      font-size: 0.95rem;
      color: #555;
      background-color: #f9f9f9;
      border-left: 3px solid #007bff;
      padding: 1rem 1.5rem;
      border-radius: 5px;
      margin-top: 1rem;
    }
    .paper-id {
      font-size: 0.85rem;
      color: #888;
      margin-left: 10px;
    }
    ul {
      padding-left: 1.5rem;
    }
    li {
      margin-bottom: 0.5rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>Hung-Ming Liu</h1>
      <p class="links">
        <a href="https://www.linkedin.com/in/hungming-liu/" target="_blank">LinkedIn</a> |
        <a href="https://github.com/hungmingliu" target="_blank">GitHub</a> |
        <a href="mailto:cyril.liu@gmail.com">Email</a>
      </p>
    </header>

    <h2>About Me</h2>
    <p>
      I am a researcher specializing in the field of artificial intelligence, with a particular focus on developing interpretable and efficient neural network architectures. My work explores how models can learn to reason using discrete symbols, aiming to create more transparent and trustworthy AI systems. My research goal is to bridge the gap between symbolism and connectionism, providing innovative solutions for multi-agent coordination and native symbolic reasoning.
    </p>

    <h2>Publications</h2>
    <div class="publication">
      <h3>
        <a href="https://arxiv.org/abs/2507.10566" target="_blank">
          Emergent Discrete Language for Multi-Agent Coordination via VQ-VAE and Communication-Aware Learning
        </a>
        <span class="paper-id">arXiv:2507.10566</span>
      </h3>
      <p><strong>Author:</strong> Hung Ming Liu</p>
      <div class="abstract">
        <p><strong>Abstract:</strong> We propose a novel architecture for addressing the "Joint Exploration Dilemma" in multi-agent reinforcement learning (MARL). By leveraging VQ-VAE for symbol grounding and introducing communication-aware reinforcement learning objectives, our system demonstrates structured language emergence that effectively supports multi-agent coordination and symbolic reasoning. Experiments show that when agents possess an endogenous symbol system, their neural representations naturally exhibit "spontaneous semantic compression" and "Nash equilibrium-driven semantic convergence," enabling effective communication without artificial inductive biases.</p>
      </div>
    </div>
    <div class="publication">
      <h3>
        <a href="https://arxiv.org/abs/2508.18988" target="_blank">
          Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models
        </a>
        <span class="paper-id">arXiv:2508.18988</span>
      </h3>
      <p><strong>Author:</strong> Hung Ming Liu</p>
      <div class="abstract">
        <p><strong>Abstract:</strong> We present a framework where neural models develop an "AI Mother Tongue," a native symbolic language that simultaneously supports intuitive reasoning, compositional symbol chains, and inherent interpretability. Unlike post-hoc explanation methods, our approach embeds reasoning directly into the models' representations: symbols capture meaningful semantic patterns, chains trace decision paths, and gated intuition mechanisms guide selective focus, yielding transparent yet flexible reasoning. We introduce complementary training objectives to enhance symbol purity and decision sparsity, and employ a sequential specialization strategy to first build broad symbolic competence and then refine intuitive judgments. Experiments on AG News demonstrate competitive accuracy alongside verifiable reasoning traces, showing that AI Mother Tongue can serve as a unified mechanism for interpretability, intuition, and symbolic reasoning in neural models.</p>
      </div>
    </div>

    <h2>Collaboration</h2>
    <p>I am open to research collaborations in the areas of:</p>
    <ul>
      <li>Emergent Communication</li>
      <li>Multi-Agent Reinforcement Learning</li>
      <li>Symbol Grounding and Discrete Representations</li>
      <li>Neuro-Symbolic AI and Interpretable Models</li>
      <li>Gated Intuition Mechanisms in Neural Networks</li>
      <li>Endogenous Symbol Systems and Semantic Compression</li>
    </ul>
    <p>Feel free to reach out via <a href="https://www.researchgate.net/profile/Hung-Ming-Liu" target="_blank">ResearchGate</a>.</p>
  </div>
</body>
</html>